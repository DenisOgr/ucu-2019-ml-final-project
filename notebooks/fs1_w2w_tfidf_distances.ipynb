{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fs1_w2w_tfidf_distances.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "ucu-2019-ml-final-project",
      "language": "python",
      "name": "myenv"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "pifUtBe1v57J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_multiple_whitespaces, remove_stopwords, stem_text\n",
        "from gensim.models import Word2Vec\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel, polynomial_kernel, sigmoid_kernel, laplacian_kernel, rbf_kernel\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from scipy.spatial.distance import cdist, directed_hausdorff\n",
        "from fastdtw import fastdtw\n",
        "#import similaritymeasures\n",
        "from scipy.spatial import procrustes\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def isCollab():\n",
        "  return os.environ.get('COLAB_GPU', None) != None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-vcqtmOMv57Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c00f9a8e-b203-470a-83d1-6941baac656a"
      },
      "cell_type": "code",
      "source": [
        "path_to_storage = os.path.abspath(os.path.join(os.getcwd(), '../storage'))\n",
        "\n",
        "if isCollab():\n",
        "  ## For Google colab (chage dir from local to GDrive)\n",
        "  ## Mount gdrive and set path to folder\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  path_to_storage = '/content/gdrive/My Drive/UCU-2019-final-project-storage'\n",
        "  #Sorry! I am realy sorry for it. But there are any other solution....\n",
        "  sys.path.append(path_to_storage)\n",
        "else:\n",
        "  sys.path.append('..')\n",
        "\n",
        "from utils.func.functions import pickle_and_remove\n",
        "  \n",
        "  \n",
        "data_folder = path_to_storage+'/data/'\n",
        "serialization_objects_folder = path_to_storage+'/serialization_objects/'"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z1mGyssgv57T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "LN3oMmod3PSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from func.functions import build_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pdpiRIEQv57U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filters = [strip_tags, strip_multiple_whitespaces, remove_stopwords, stem_text]\n",
        "def tokenize(data_type='train'):\n",
        "    if data_type=='test':\n",
        "        X = pickle.load(open(serialization_objects_folder+'X_test.p', 'rb'))\n",
        "    else:\n",
        "        X = pickle.load(open(serialization_objects_folder+'X_train.p', 'rb'))\n",
        "    series = pd.Series(pd.concat([X['question1'], X['question2']]),dtype=str)\n",
        "    series.dropna()\n",
        "    for question in series:\n",
        "        yield preprocess_string(question, filters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DmK8ZlOtv57X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenize_for_model(model, data_type):\n",
        "    \"\"\"\n",
        "    This function tokenize and check token for dict in model\n",
        "    :param:  model, data_type\n",
        "    :return: ndarray \n",
        "    \"\"\"\n",
        "    for question in tokenize(data_type=data_type):\n",
        "        tf_idf_tokens = []\n",
        "        for token in question:\n",
        "            try:\n",
        "                vector = model.wv[token]\n",
        "                tf_idf_tokens.append(token)\n",
        "            except:\n",
        "                continue\n",
        "        yield np.array(tf_idf_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Aqp4rHPNv57Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "metadata": {
        "id": "lhU1kbHgv57a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Embedding: word2vec (Transfer-train on training data)"
      ]
    },
    {
      "metadata": {
        "id": "xjhrHi4Yv57b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenized_questions = [question for question in tokenize(data_type='train')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z6b96e2bv57d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_w2v = Word2Vec(tokenized_questions, size=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MiLbElLRv57g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_w2v.intersect_word2vec_format(data_folder+'GoogleNews-vectors-negative300.bin',\n",
        "                                lockf=1.0,\n",
        "                                binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LUqYRK2Ov57j",
        "colab_type": "code",
        "colab": {},
        "outputId": "36d4b2f2-4d61-4f81-f694-5d9614326e07"
      },
      "cell_type": "code",
      "source": [
        "model_w2v.train(tokenized_questions,total_examples=model_w2v.corpus_count, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28526660, 35550940)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "M53qGfRwv57s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Feature Sets 1 - Pairwise Distance & word2vec Vectors"
      ]
    },
    {
      "metadata": {
        "id": "bAYEZb5Nv57t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train - TF-IDF Vectorizer and TF-IDF Weights + word2vec Vectors\n"
      ]
    },
    {
      "metadata": {
        "id": "HPwJtvVHv57t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = pickle.load(open(serialization_objects_folder+'X_train.p', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qgd78u8nv57v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pass_through = lambda x:x\n",
        "tfidf = TfidfVectorizer(analyzer=pass_through)\n",
        "X_tfidf_all_q = tfidf.fit_transform(tokenize_for_model(model=model_w2v,data_type='train'))\n",
        "X_q1_tfidf = X_tfidf_all_q[:len(X_train)]\n",
        "X_q2_tfidf = X_tfidf_all_q[len(X_train):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7dw9pddcv57x",
        "colab_type": "code",
        "colab": {},
        "outputId": "a9b2b554-5b43-49ff-bd55-9c0ef39a9b3d"
      },
      "cell_type": "code",
      "source": [
        "#X1_q1_tfidf[0] - sparsed vector with float (tfidf)\n",
        "X_q1_tfidf.shape, X_q2_tfidf.shape, X_train.shape, X_q1_tfidf[0,X_q1_tfidf[0].todense().nonzero()[1]].todense()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((270872, 31889),\n",
              " (270872, 31889),\n",
              " (270872, 4),\n",
              " matrix([[0.56637731, 0.66474651, 0.14063621, 0.46642286]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "NPFilyUlv57z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function to compute TF-IDF weights as well as the word2vec vectors for all tokens\n",
        "def get_weights_and_w2vectors(tfidf_matrix, tfidf_vectorizer, model):\n",
        "    weights = []\n",
        "    vectors = []\n",
        "    rows = tfidf_matrix.shape[0]\n",
        "    inverse_vocab_dict = {v: k for k, v in tfidf_vectorizer.vocabulary_.items()}\n",
        "    for doc in range(rows):\n",
        "        features = tfidf_matrix[doc,:].nonzero()[1]\n",
        "        #weights[i] - all tfidf value for i- row (len(w[i]) - number token/words in row/question)\n",
        "        weights.append(np.array([tfidf_matrix[doc, x] for x in features]))\n",
        "        #vectors[i] - all vectors embeded from model. (len(w[i]) - number token/words in row/question)\n",
        "        vectors.append(np.array([model.wv[inverse_vocab_dict[x]] for x in features]))\n",
        "    return np.array(weights), np.array(vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQAia0sDv571",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ssb2HtH-v573",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Train set"
      ]
    },
    {
      "metadata": {
        "id": "a0oiDvbWv573",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_q1_tfidf, X_q1_w2v_vect = get_weights_and_w2vectors(X_q1_tfidf, tfidf, model_w2v)\n",
        "X_q2_tfidf, X_q2_w2v_vect = get_weights_and_w2vectors(X_q2_tfidf, tfidf, model_w2v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QA9LyVJKv575",
        "colab_type": "code",
        "colab": {},
        "outputId": "8ca07771-399b-416b-f28a-4b80ac11a42d"
      },
      "cell_type": "code",
      "source": [
        "#first row\n",
        "X_q1_tfidf[0].shape, X_q1_w2v_vect[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4,), (4, 300))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "cBEcb0sTv578",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pickle.dump(X_q1_tfidf, open(serialization_objects_folder+'X_train_q1_tfidf.p','wb'))\n",
        "pickle.dump(X_q2_tfidf, open(serialization_objects_folder+'X_train_q2_tfidf.p','wb'))\n",
        "pickle.dump(X_q1_w2v_vect, open(serialization_objects_folder+'X_train_q1_w2v_vect.p','wb'))\n",
        "pickle.dump(X_q2_w2v_vect, open(serialization_objects_folder+'X_train_q2_w2v_vect.p','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ks0opf2v57-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del X_q1_tfidf, X_q1_w2v_vect, X_q2_tfidf, X_q2_w2v_vect, X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1GbAxQ6qv58A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Test set"
      ]
    },
    {
      "metadata": {
        "id": "5d_qlPWmv58B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test = pickle.load(open(serialization_objects_folder+'X_test.p', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oWWPMfliv58D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_tfidf_all_q = tfidf.transform(tokenize_for_model(model=model_w2v,data_type='test'))\n",
        "# split back into two\n",
        "X_q1_tfidf = X_tfidf_all_q[:len(X_test)]\n",
        "X_q2_tfidf = X_tfidf_all_q[len(X_test):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yWVfM01nv58F",
        "colab_type": "code",
        "colab": {},
        "outputId": "1d93a509-7296-4e6b-dc1f-aeb3c3d59308"
      },
      "cell_type": "code",
      "source": [
        "#X1_q1_tfidf[0] - sparsed vector with float (tfidf)\n",
        "X_q1_tfidf.shape, X_q2_tfidf.shape, X_test.shape, X_q1_tfidf[0,X_q1_tfidf[0].todense().nonzero()[1]].todense()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((133415, 31889),\n",
              " (133415, 31889),\n",
              " (133415, 4),\n",
              " matrix([[0.41021448, 0.3659877 , 0.61066633, 0.56996817]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "lEK04n13v58H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_q1_tfidf, X_q1_w2v_vect = get_weights_and_w2vectors(X_q1_tfidf, tfidf, model_w2v)\n",
        "X_q2_tfidf, X_q2_w2v_vect = get_weights_and_w2vectors(X_q2_tfidf, tfidf, model_w2v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jLwq4kg6v58J",
        "colab_type": "code",
        "colab": {},
        "outputId": "df9e472b-ffe0-46ea-9613-2fcc540cfb33"
      },
      "cell_type": "code",
      "source": [
        "#first row\n",
        "X_q1_tfidf[0].shape, X_q1_w2v_vect[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4,), (4, 300))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "fdDnwU_Wv58L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pickle.dump(X_q1_tfidf, open(serialization_objects_folder+'X_test_q1_tfidf.p','wb'))\n",
        "pickle.dump(X_q2_tfidf, open(serialization_objects_folder+'X_test_q2_tfidf.p','wb'))\n",
        "pickle.dump(X_q1_w2v_vect, open(serialization_objects_folder+'X_test_q1_w2v_vect.p','wb'))\n",
        "pickle.dump(X_q2_w2v_vect, open(serialization_objects_folder+'X_test_q2_w2v_vect.p','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GGsGRioDv58M",
        "colab_type": "code",
        "colab": {},
        "outputId": "fc78244c-122e-4036-c176-e8d748aaefbb"
      },
      "cell_type": "code",
      "source": [
        "!ls \"$serialization_objects_folder\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_test.p              X_train.p             readme\r\n",
            "X_test_q1_tfidf.p     X_train_q1_tfidf.p    y_test.p\r\n",
            "X_test_q1_w2v_vect.p  X_train_q1_w2v_vect.p y_train.p\r\n",
            "X_test_q2_tfidf.p     X_train_q2_tfidf.p\r\n",
            "X_test_q2_w2v_vect.p  X_train_q2_w2v_vect.p\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qWRDbxwKv58O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del X_q1_tfidf, X_q1_w2v_vect, X_q2_tfidf, X_q2_w2v_vect, X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p5xTW4a3v58Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del model_w2v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zm0dT7cgv58R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Pairwise Distances & Weighted Means"
      ]
    },
    {
      "metadata": {
        "id": "zgEhYIjWv58S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_nan_array(r,c):\n",
        "    arr = np.empty((r,c))\n",
        "    arr[:] = np.nan\n",
        "    return arr\n",
        "def compute_pairwise_kernel(pc1, pc2, w1, w2, method='linear'):\n",
        "    if pc1.size == 0 or pc2.size == 0:\n",
        "        return np.nan\n",
        "    if method=='polynomial':\n",
        "        dist_mat = polynomial_kernel(pc1, pc2, 2)\n",
        "    elif method=='rbf':\n",
        "        dist_mat = rbf_kernel(pc1, pc2)\n",
        "    elif method=='sigmoid':\n",
        "        dist_mat = sigmoid_kernel(pc1, pc2)\n",
        "    elif method=='laplacian':\n",
        "        dist_mat = laplacian_kernel(pc1, pc2)\n",
        "    else:\n",
        "        dist_mat = linear_kernel(pc1, pc2)\n",
        "    return np.average(dist_mat, weights=np.matmul(w1.reshape(-1,1),w2.reshape(-1,1).T))\n",
        "\n",
        "def compute_pairwise_dist(pc1, pc2, w1, w2, method='euclidean'):\n",
        "    if pc1.size == 0 or pc2.size == 0:\n",
        "        return np.nan\n",
        "    if method=='hausdorff':\n",
        "        dist = directed_hausdorff(pc1, pc2)\n",
        "        return dist[0]\n",
        "    else:\n",
        "        dist_mat = pairwise_distances(pc1, pc2, metric=method) \n",
        "\n",
        "    return np.average(dist_mat, weights=np.matmul(w1.reshape(-1,1),w2.reshape(-1,1).T))\n",
        "\n",
        "def compute_pairwise_for_dataset(X1, X2, X1_w, X2_w, method):\n",
        "    temp = []\n",
        "    for q_tuple in zip(X1, X2, X1_w, X2_w):\n",
        "        if q_tuple:\n",
        "            q1_rd, q2_rd, q1_w, q2_w = q_tuple\n",
        "            if method in ['polynomial', 'rbf', 'sigmoid', 'laplacian', 'linear']:\n",
        "                temp.append(compute_pairwise_kernel(q1_rd, q2_rd, q1_w, q2_w, method))\n",
        "            else:\n",
        "                temp.append(compute_pairwise_dist(q1_rd, q2_rd, q1_w, q2_w, method))\n",
        "        else:\n",
        "            temp.append(np.nan)\n",
        "    return temp\n",
        "\n",
        "def compute_pairwise_for_dataset_wmean(X, X_w, file, store_folder):\n",
        "    temp = []\n",
        "    for q_tuple in zip(X, X_w):\n",
        "        if q_tuple:\n",
        "            q_rd, q_w = q_tuple\n",
        "            if np.sum(q_w) != 0:\n",
        "                temp.append(compute_weighted_mean(q_rd, q_w))\n",
        "            else:\n",
        "                temp.append(create_nan_array(1,300))                    \n",
        "        else:\n",
        "            temp.append(create_nan_array(1,300))\n",
        "    temp_arr = np.array(temp)\n",
        "    pickle_and_remove(temp_arr, file, store_folder) \n",
        "\n",
        "    # computes pairwise metrics, weighted mean and saves to store_folder \n",
        "def compute_and_save(X1, X2, X1_w, X2_w, method, file, store_folder):\n",
        "    computed_obj = compute_pairwise_for_dataset(X1, X2, X1_w, X2_w, method)\n",
        "    pickle_and_remove(computed_obj, file, store_folder) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9km6H4Ymv58U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "distances = ['chebyshev','braycurtis', 'cosine', 'correlation', 'canberra', 'hausdorff', 'cityblock',\n",
        "            'euclidean', 'l1', 'l2', 'manhattan', 'minkowski', 'sqeuclidean']\n",
        "\n",
        "def compute_and_save_for_all(X1, X2, X1_w, X2_w, distance, data_type, store_folder):\n",
        "    name=\"%s_%s_w\"%(distance, data_type)\n",
        "    print(distance)\n",
        "    compute_and_save(X1, X2, X1_w, X2_w, distance, name, store_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p22dK0Gyv58W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Train set"
      ]
    },
    {
      "metadata": {
        "id": "okf7Gl_Nv58W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X1_w = pickle.load(open(serialization_objects_folder+'X_train_q1_tfidf.p','rb'))\n",
        "X2_w = pickle.load(open(serialization_objects_folder+'X_train_q2_tfidf.p','rb'))\n",
        "X1 = pickle.load(open(serialization_objects_folder+'X_train_q1_w2v_vect.p','rb'))\n",
        "X2 = pickle.load(open(serialization_objects_folder+'X_train_q2_w2v_vect.p','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PocZY2brv58Y",
        "colab_type": "code",
        "colab": {},
        "outputId": "43bd79cd-4738-42ff-f0de-eef21d0ec6f6"
      },
      "cell_type": "code",
      "source": [
        "X1_w[0].shape,X1[0].shape,X2_w[0].shape,X2[0].shape,"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4,), (4, 300), (6,), (6, 300))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "3HUoM1rCv58a",
        "colab_type": "code",
        "colab": {},
        "outputId": "94e530b9-bb1d-4e82-b62b-09f684cd4704"
      },
      "cell_type": "code",
      "source": [
        "#Run for train\n",
        "data_type = 'train'\n",
        "store_folder = serialization_objects_folder\n",
        "\n",
        "for distance in distances:\n",
        "    compute_and_save_for_all(X1, X2, X1_w, X2_w, distance, data_type, store_folder)\n",
        "\n",
        "compute_and_save_mean_for_all('weighted_mean1', X1,X1_w, data_type, store_folder)\n",
        "compute_and_save_mean_for_all('weighted_mean2', X2,X2_w, data_type, store_folder)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chebyshev\n",
            "braycurtis\n",
            "cosine\n",
            "correlation\n",
            "canberra\n",
            "hausdorff\n",
            "cityblock\n",
            "euclidean\n",
            "l1\n",
            "l2\n",
            "manhattan\n",
            "minkowski\n",
            "sqeuclidean\n",
            "sqeuclidean\n",
            "sqeuclidean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F26STY37v58c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del X1_w, X2_w, X1, X2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kIsSmz23v58e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Test set"
      ]
    },
    {
      "metadata": {
        "id": "nNI-J8CUv58e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X1_w = pickle.load(open(serialization_objects_folder+'X_test_q1_tfidf.p','rb'))\n",
        "X2_w = pickle.load(open(serialization_objects_folder+'X_test_q2_tfidf.p','rb'))\n",
        "X1 = pickle.load(open(serialization_objects_folder+'X_test_q1_w2v_vect.p','rb'))\n",
        "X2 = pickle.load(open(serialization_objects_folder+'X_test_q2_w2v_vect.p','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PqSJxkwNv58f",
        "colab_type": "code",
        "colab": {},
        "outputId": "136d528b-3d27-4e7e-ddc5-e1c751e7bb22"
      },
      "cell_type": "code",
      "source": [
        "X1_w[0].shape,X1[0].shape,X2_w[0].shape,X2[0].shape,"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4,), (4, 300), (5,), (5, 300))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "-SwlD78Fv58k",
        "colab_type": "code",
        "colab": {},
        "outputId": "ec1ea5fc-3672-4559-e326-878724884dbe"
      },
      "cell_type": "code",
      "source": [
        "#Run for train\n",
        "data_type = 'test'\n",
        "store_folder = serialization_objects_folder\n",
        "\n",
        "for distance in distances:\n",
        "    compute_and_save_for_all(X1, X2, X1_w, X2_w, distance, data_type, store_folder)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chebyshev\n",
            "braycurtis\n",
            "cosine\n",
            "correlation\n",
            "canberra\n",
            "hausdorff\n",
            "cityblock\n",
            "euclidean\n",
            "l1\n",
            "l2\n",
            "manhattan\n",
            "minkowski\n",
            "sqeuclidean\n",
            "sqeuclidean\n",
            "sqeuclidean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "W5FQ4s0jv58m",
        "colab_type": "code",
        "colab": {},
        "outputId": "bd801526-bda0-4a3c-e366-6b130e6636ed"
      },
      "cell_type": "code",
      "source": [
        "!ls \"$serialization_objects_folder\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1_train.p              canberra_train_w.p     l1_train_w.p\r\n",
            "X_test.p               chebyshev_test_w.p     l2_test_w.p\r\n",
            "X_test_q1_tfidf.p      chebyshev_train_w.p    l2_train_w.p\r\n",
            "X_test_q1_w2v_vect.p   cityblock_test_w.p     manhattan_test_w.p\r\n",
            "X_test_q2_tfidf.p      cityblock_train_w.p    manhattan_train_w.p\r\n",
            "X_test_q2_w2v_vect.p   correlation_test_w.p   minkowski_test_w.p\r\n",
            "X_train.p              correlation_train_w.p  minkowski_train_w.p\r\n",
            "X_train_q1_tfidf.p     cosine_test_w.p        readme\r\n",
            "X_train_q1_w2v_vect.p  cosine_train_w.p       sqeuclidean_test_w.p\r\n",
            "X_train_q2_tfidf.p     euclidean_test_w.p     sqeuclidean_train_w.p\r\n",
            "X_train_q2_w2v_vect.p  euclidean_train_w.p    weighted_mean2_train.p\r\n",
            "braycurtis_test_w.p    hausdorff_test_w.p     y_test.p\r\n",
            "braycurtis_train_w.p   hausdorff_train_w.p    y_train.p\r\n",
            "canberra_test_w.p      l1_test_w.p\r\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}