{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "wVYAgEXBvbTt",
    "outputId": "04e334fa-7ed9-4980-b07f-9061a5ee6fec"
   },
   "outputs": [],
   "source": [
    "#in: build X with utils/function build_X('test|train')\n",
    "#out: metrics(acc, recall, prec), roc_curve, log_loss\n",
    "#Google Colab needs\n",
    "import os\n",
    "import sys\n",
    "def isCollab():\n",
    "    return os.environ.get('COLAB_GPU', None) != None\n",
    "\n",
    "if isCollab():\n",
    "    #Mounting GDrive disc\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    path_to_storage = '/content/gdrive/My Drive/UCU-2019-final-project-storage'\n",
    "\n",
    "    #Append path where custom modules stored. I put custom modules to GDrive disc\n",
    "    path_to_modules = '/content/gdrive/My Drive/UCU-2019-final-project-storage'\n",
    "    sys.path.append(path_to_modules)\n",
    "else:\n",
    "    sys.path.append('..')\n",
    "    path_to_storage = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNJoM-rfwvOS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/denisporplenko/anaconda3/envs/ucu-2019-ml-final-project/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import re\n",
    "from keras import optimizers\n",
    "from keras import activations\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from keras import layers\n",
    "from keras import activations\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "from keras import metrics\n",
    "from keras import Input\n",
    "import gensim\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading training data and word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AvEOuuv6BkId"
   },
   "outputs": [],
   "source": [
    "if not path_to_storage:\n",
    "    path_to_storage = os.path.abspath(os.path.join(os.getcwd(), '../storage')) \n",
    "\n",
    "path_to_objects = path_to_storage + \"/serialization_objects/\"\n",
    "data_folder = path_to_storage+'/data/'\n",
    "X_train = pickle.load(open(path_to_objects + 'X_train.p', 'rb'))\n",
    "y_train = pickle.load(open(path_to_objects + 'y_train.p', 'rb'))\n",
    "X_test = pickle.load(open(path_to_objects + 'X_test.p', 'rb'))\n",
    "y_test = pickle.load(open(path_to_objects + 'y_test.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_vecs_train = pickle.load(open(path_to_objects + 'X_train_q1_w2v_vect.p', 'rb'))\n",
    "q2_vecs_train = pickle.load(open(path_to_objects + 'X_train_q2_w2v_vect.p', 'rb'))\n",
    "q1_vecs_test = pickle.load(open(path_to_objects + 'X_test_q1_w2v_vect.p', 'rb'))\n",
    "q2_vecs_test = pickle.load(open(path_to_objects + 'X_test_q2_w2v_vect.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train['question1'] = q1_vecs_train\n",
    "X_train['question2'] = q2_vecs_train\n",
    "X_test['question1'] = q1_vecs_test\n",
    "X_test['question2'] = q2_vecs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "m0I5RNGyRHPT"
   },
   "outputs": [],
   "source": [
    "max_seq_length = max(X_train.question1.map(lambda x:len(x)).max(),\n",
    "                    X_train.question2.map(lambda x:len(x)).max(),\n",
    "                    X_test.question1.map(lambda x:len(x)).max(),\n",
    "                    X_test.question2.map(lambda x:len(x)).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iwVKQc186CEb"
   },
   "outputs": [],
   "source": [
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n",
    "\n",
    "  \n",
    "n_hidden = 50\n",
    "gradient_clipping_norm  = 1.25\n",
    "\n",
    "batch_size = 64\n",
    "n_epoch = 3\n",
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iwVKQc186CEb"
   },
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(len(embeddings), embedding_dim, weights=[embeddings], input_length=max_seq_length, trainable=False)\n",
    "\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n",
    "shared_lstm = keras.layers.LSTM(n_hidden)\n",
    "\n",
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)\n",
    "\n",
    "distance = keras.layers.Lambda(function=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n",
    "\n",
    "\n",
    "model = Model([left_input, right_input], [distance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aIC-jGqFYXAt"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "optimizer = optimizers.Adam(clipnorm=gradient_clipping_norm)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kQ4yeSzaZH9u"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "# Split to train validation\n",
    "validation_size = 40000\n",
    "training_size = len(X_train) - validation_size\n",
    "\n",
    "X = X_train[questions_cols]\n",
    "Y = y_train\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size)\n",
    "\n",
    "X_train = {'left': X_train.question1, 'right': X_train.question2}\n",
    "X_validation = {'left': X_validation.question1, 'right': X_validation.question2}\n",
    "X_test = {'left': X_test.question1, 'right': X_test.question2}\n",
    "\n",
    "Y_train = Y_train.values\n",
    "Y_validation = Y_validation.values\n",
    "\n",
    "X_train['left'] = pad_sequences(X_train['left'],  maxlen=max_seq_length)\n",
    "X_train['right'] = pad_sequences(X_train['right'],  maxlen=max_seq_length)\n",
    "X_validation['left'] = pad_sequences(X_validation['left'],  maxlen=max_seq_length)\n",
    "X_validation['right'] = pad_sequences(X_validation['right'],  maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "VSupc6JHY3v4",
    "outputId": "c9eba18b-017f-4202-c0a8-77c3e3740fe5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 230872 samples, validate on 40000 samples\n",
      "Epoch 1/3\n",
      "230872/230872 [==============================] - 11446s 50ms/step - loss: 0.1806 - acc: 0.7353 - val_loss: 0.1643 - val_acc: 0.7633\n",
      "Epoch 2/3\n",
      "230872/230872 [==============================] - 11341s 49ms/step - loss: 0.1588 - acc: 0.7743 - val_loss: 0.1545 - val_acc: 0.7830\n",
      "Epoch 3/3\n",
      "230872/230872 [==============================] - 11317s 49ms/step - loss: 0.1506 - acc: 0.7893 - val_loss: 0.1498 - val_acc: 0.7890\n"
     ]
    }
   ],
   "source": [
    "trained = model.fit([X_train['left'], X_train['right']], Y_train, batch_size=batch_size, nb_epoch=n_epoch,\n",
    "                            validation_data=([X_validation['left'], X_validation['right']], Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "F6KTS6-Fu9yU"
   },
   "outputs": [],
   "source": [
    "pickle.dump(trained, open(path_to_objects+\"lstm_trained.p\", 'wb'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model_nn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
